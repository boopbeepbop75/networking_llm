{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import kagglehub\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, IterableDataset\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import math\n",
    "import json\n",
    "import time\n",
    "import wandb\n",
    "\n",
    "# Navigate up to the project root and add it to sys.path\n",
    "project_root = Path().resolve().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "from data_loading.tools import reduce_mem_usage\n",
    "\n",
    "OVERWRITE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined data path: /home/riley/networking_llm/src/eda/../../data/luflow_combined.csv\n"
     ]
    }
   ],
   "source": [
    "# Path to the cached dataset\n",
    "cache_path = os.path.expanduser(\"~/.cache/kagglehub/datasets\")\n",
    "data_path = os.path.join(cache_path, \"mryanm/luflow-network-intrusion-detection-data-set/versions/240\")\n",
    "curr_dir = os.getcwd()\n",
    "src_dir = os.path.join(curr_dir, os.pardir)\n",
    "combined_data_path = os.path.join(src_dir, os.pardir, \"data\", \"luflow_combined.csv\")\n",
    "\n",
    "if not (os.path.exists(data_path) or os.path.exists(combined_data_path)) or OVERWRITE: # if either of the paths exist, don't download\n",
    "    # Download latest version\n",
    "    data_path = kagglehub.dataset_download(\"mryanm/luflow-network-intrusion-detection-data-set\")\n",
    "\n",
    "if os.path.exists(combined_data_path) and not OVERWRITE:\n",
    "    print(f\"Combined data path: {combined_data_path}\")\n",
    "else:\n",
    "    print(f\"Data path: {data_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is in different folders seperated by year, month, and day. For ease of loading, I opted to combine these into a single csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_luflow(data_path, save_path):\n",
    "    first_write = True  # Track if it's the first write to include headers\n",
    "\n",
    "    # Load and combine each CSV\n",
    "    for year in tqdm(sorted(os.listdir(data_path))):  # Sorting for consistency\n",
    "        year_path = os.path.join(data_path, year)\n",
    "        if os.path.isdir(year_path):\n",
    "            for month in sorted(os.listdir(year_path)):\n",
    "                month_path = os.path.join(year_path, month)\n",
    "                if os.path.isdir(month_path):\n",
    "                    for day in sorted(os.listdir(month_path)):\n",
    "                        day_path = os.path.join(month_path, day)\n",
    "                        if os.path.isdir(day_path):\n",
    "                            for file in os.listdir(day_path):\n",
    "                                if file.endswith(\".csv\"):\n",
    "                                    full_path = os.path.join(day_path, file)\n",
    "\n",
    "                                    # Read in chunks (adjust chunksize as needed)\n",
    "                                    for chunk in pd.read_csv(full_path, chunksize=10_000):\n",
    "                                        # Extract date info\n",
    "                                        try:\n",
    "                                            y, m, d = map(int, file.split(\".\")[:3])\n",
    "                                            chunk[\"Year\"] = y\n",
    "                                            chunk[\"Month\"] = m\n",
    "                                            chunk[\"Day\"] = d\n",
    "                                            chunk['label'] = pd.Categorical(chunk['label']).codes\n",
    "                                        except ValueError:\n",
    "                                            print(f\"Skipping malformed filename: {file}\")\n",
    "                                            continue\n",
    "\n",
    "                                        # Append to file (write header only once)\n",
    "                                        chunk.to_csv(save_path, mode='a', header=first_write, index=False)\n",
    "                                        first_write = False  # Only write header in the first batch\n",
    "\n",
    "    print(f\"Finished merging CSVs into {save_path}\")\n",
    "\n",
    "if not os.path.exists(combined_data_path) or OVERWRITE:\n",
    "    save_luflow(data_path, combined_data_path)\n",
    "    # remove cache data_path\n",
    "    os.system(f\"rm -rf {data_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 443.46 MB\n",
      "Decreased by 59.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/riley/networking_llm/lib/python3.10/site-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
      "  has_large_values = (abs_vals > 1e6).any()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_ipt</th>\n",
       "      <th>bytes_in</th>\n",
       "      <th>bytes_out</th>\n",
       "      <th>dest_ip</th>\n",
       "      <th>dest_port</th>\n",
       "      <th>entropy</th>\n",
       "      <th>num_pkts_out</th>\n",
       "      <th>num_pkts_in</th>\n",
       "      <th>proto</th>\n",
       "      <th>src_ip</th>\n",
       "      <th>src_port</th>\n",
       "      <th>time_end</th>\n",
       "      <th>time_start</th>\n",
       "      <th>total_entropy</th>\n",
       "      <th>label</th>\n",
       "      <th>duration</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.500000</td>\n",
       "      <td>342</td>\n",
       "      <td>3679</td>\n",
       "      <td>786</td>\n",
       "      <td>9200.0</td>\n",
       "      <td>5.437500</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>786</td>\n",
       "      <td>57392.0</td>\n",
       "      <td>1592533725648144</td>\n",
       "      <td>1592533725632946</td>\n",
       "      <td>21860.917969</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015198</td>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>786</td>\n",
       "      <td>55972.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>49453</td>\n",
       "      <td>49493.0</td>\n",
       "      <td>1592533744644904</td>\n",
       "      <td>1592533744644904</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>15440</td>\n",
       "      <td>942</td>\n",
       "      <td>786</td>\n",
       "      <td>9300.0</td>\n",
       "      <td>2.203125</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>786</td>\n",
       "      <td>60512.0</td>\n",
       "      <td>1592533770936279</td>\n",
       "      <td>1592533770933553</td>\n",
       "      <td>36091.753906</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002726</td>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.217392</td>\n",
       "      <td>622</td>\n",
       "      <td>31010</td>\n",
       "      <td>786</td>\n",
       "      <td>9300.0</td>\n",
       "      <td>1.190430</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>786</td>\n",
       "      <td>60490.0</td>\n",
       "      <td>159253376770238</td>\n",
       "      <td>15925337672353</td>\n",
       "      <td>37640.355469</td>\n",
       "      <td>0</td>\n",
       "      <td>0.467041</td>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>786</td>\n",
       "      <td>59498.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>786</td>\n",
       "      <td>9300.0</td>\n",
       "      <td>1592533772973114</td>\n",
       "      <td>1592533772973087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     avg_ipt  bytes_in  bytes_out  dest_ip  dest_port   entropy  num_pkts_out  \\\n",
       "0   7.500000       342       3679      786     9200.0  5.437500             2   \n",
       "1   0.000000         0          0      786    55972.0  0.000000             1   \n",
       "2   0.500000     15440        942      786     9300.0  2.203125             3   \n",
       "3  20.217392       622      31010      786     9300.0  1.190430            23   \n",
       "4   0.000000         0          0      786    59498.0  0.000000             1   \n",
       "\n",
       "   num_pkts_in  proto  src_ip  src_port          time_end        time_start  \\\n",
       "0            2      6     786   57392.0  1592533725648144  1592533725632946   \n",
       "1            1      6   49453   49493.0  1592533744644904  1592533744644904   \n",
       "2            3      6     786   60512.0  1592533770936279  1592533770933553   \n",
       "3            5      6     786   60490.0   159253376770238    15925337672353   \n",
       "4            1      6     786    9300.0  1592533772973114  1592533772973087   \n",
       "\n",
       "   total_entropy  label  duration  Year  Month  Day  \n",
       "0   21860.917969      0  0.015198  2020      6   19  \n",
       "1       0.000000      2  0.000000  2020      6   19  \n",
       "2   36091.753906      0  0.002726  2020      6   19  \n",
       "3   37640.355469      0  0.467041  2020      6   19  \n",
       "4       0.000000      0  0.000027  2020      6   19  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(combined_data_path, nrows=7_500_000)\n",
    "data = reduce_mem_usage(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7500000 entries, 0 to 7499999\n",
      "Data columns (total 19 columns):\n",
      " #   Column         Dtype  \n",
      "---  ------         -----  \n",
      " 0   avg_ipt        float32\n",
      " 1   bytes_in       int32  \n",
      " 2   bytes_out      int32  \n",
      " 3   dest_ip        int32  \n",
      " 4   dest_port      float32\n",
      " 5   entropy        float16\n",
      " 6   num_pkts_out   int16  \n",
      " 7   num_pkts_in    int16  \n",
      " 8   proto          int8   \n",
      " 9   src_ip         int32  \n",
      " 10  src_port       float32\n",
      " 11  time_end       int64  \n",
      " 12  time_start     int64  \n",
      " 13  total_entropy  float32\n",
      " 14  label          int8   \n",
      " 15  duration       float16\n",
      " 16  Year           int16  \n",
      " 17  Month          int8   \n",
      " 18  Day            int8   \n",
      "dtypes: float16(2), float32(4), int16(3), int32(4), int64(2), int8(4)\n",
      "memory usage: 443.5 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Day\n",
       "22    4204081\n",
       "21     814816\n",
       "20     770853\n",
       "19     765360\n",
       "23     637677\n",
       "24     307213\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Day'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full dataset is too large to get description stats in a timely manner, so only inspecting a subset. NaN seen for some mean values due to overflow during summation, a consequence of downcasting as we've done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/riley/networking_llm/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n",
      "  return dtype.type(n)\n",
      "/home/riley/networking_llm/lib/python3.10/site-packages/numpy/_core/_methods.py:53: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n",
      "/home/riley/networking_llm/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  the_mean = the_sum / count if count > 0 else np.nan\n",
      "/home/riley/networking_llm/lib/python3.10/site-packages/pandas/core/nanops.py:1487: RuntimeWarning: overflow encountered in cast\n",
      "  return dtype.type(n)\n",
      "/home/riley/networking_llm/lib/python3.10/site-packages/numpy/_core/_methods.py:53: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n",
      "/home/riley/networking_llm/lib/python3.10/site-packages/pandas/core/nanops.py:731: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  the_mean = the_sum / count if count > 0 else np.nan\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_ipt</th>\n",
       "      <th>bytes_in</th>\n",
       "      <th>bytes_out</th>\n",
       "      <th>dest_ip</th>\n",
       "      <th>dest_port</th>\n",
       "      <th>entropy</th>\n",
       "      <th>num_pkts_out</th>\n",
       "      <th>num_pkts_in</th>\n",
       "      <th>proto</th>\n",
       "      <th>src_ip</th>\n",
       "      <th>src_port</th>\n",
       "      <th>time_end</th>\n",
       "      <th>time_start</th>\n",
       "      <th>total_entropy</th>\n",
       "      <th>label</th>\n",
       "      <th>duration</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7.500000e+06</td>\n",
       "      <td>7.500000e+06</td>\n",
       "      <td>7.500000e+06</td>\n",
       "      <td>7.500000e+06</td>\n",
       "      <td>7.500000e+06</td>\n",
       "      <td>7.500000e+06</td>\n",
       "      <td>7.500000e+06</td>\n",
       "      <td>7.500000e+06</td>\n",
       "      <td>7.500000e+06</td>\n",
       "      <td>7.500000e+06</td>\n",
       "      <td>7.500000e+06</td>\n",
       "      <td>7.500000e+06</td>\n",
       "      <td>7.500000e+06</td>\n",
       "      <td>7.500000e+06</td>\n",
       "      <td>7.500000e+06</td>\n",
       "      <td>7.500000e+06</td>\n",
       "      <td>7500000.0</td>\n",
       "      <td>7500000.0</td>\n",
       "      <td>7.500000e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.515988e+06</td>\n",
       "      <td>1.004937e+03</td>\n",
       "      <td>4.602249e+03</td>\n",
       "      <td>1.652941e+03</td>\n",
       "      <td>1.372595e+04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.413012e+00</td>\n",
       "      <td>3.285689e+00</td>\n",
       "      <td>7.047596e+00</td>\n",
       "      <td>1.653160e+04</td>\n",
       "      <td>3.657185e+04</td>\n",
       "      <td>1.452405e+15</td>\n",
       "      <td>1.449253e+15</td>\n",
       "      <td>1.702605e+04</td>\n",
       "      <td>4.630831e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.154660e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.287582e+07</td>\n",
       "      <td>4.473974e+03</td>\n",
       "      <td>6.907070e+03</td>\n",
       "      <td>8.210696e+03</td>\n",
       "      <td>1.606385e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.262336e+01</td>\n",
       "      <td>1.204337e+01</td>\n",
       "      <td>3.440329e+00</td>\n",
       "      <td>3.993376e+04</td>\n",
       "      <td>1.859831e+04</td>\n",
       "      <td>4.286313e+14</td>\n",
       "      <td>4.328397e+14</td>\n",
       "      <td>6.049262e+04</td>\n",
       "      <td>7.219262e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.217167e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>1.592536e+10</td>\n",
       "      <td>1.592537e+10</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.900000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.700000e+01</td>\n",
       "      <td>7.860000e+02</td>\n",
       "      <td>1.900000e+03</td>\n",
       "      <td>2.035156e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>7.860000e+02</td>\n",
       "      <td>1.430600e+04</td>\n",
       "      <td>1.592637e+15</td>\n",
       "      <td>1.592633e+15</td>\n",
       "      <td>9.736174e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.297495e-05</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.100000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.670000e+02</td>\n",
       "      <td>7.860000e+02</td>\n",
       "      <td>9.200000e+03</td>\n",
       "      <td>3.089844e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>7.860000e+02</td>\n",
       "      <td>4.446400e+04</td>\n",
       "      <td>1.592796e+15</td>\n",
       "      <td>1.592796e+15</td>\n",
       "      <td>8.341838e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.149774e-04</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.200000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.500000e+00</td>\n",
       "      <td>2.700000e+02</td>\n",
       "      <td>8.688000e+03</td>\n",
       "      <td>7.860000e+02</td>\n",
       "      <td>9.200000e+03</td>\n",
       "      <td>4.832031e+00</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>8.048000e+03</td>\n",
       "      <td>4.910200e+04</td>\n",
       "      <td>1.592801e+15</td>\n",
       "      <td>1.592801e+15</td>\n",
       "      <td>2.654445e+04</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.381897e-02</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.200000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.294967e+09</td>\n",
       "      <td>6.551200e+04</td>\n",
       "      <td>6.553400e+04</td>\n",
       "      <td>3.969980e+05</td>\n",
       "      <td>6.553500e+04</td>\n",
       "      <td>8.737500e+01</td>\n",
       "      <td>2.550000e+02</td>\n",
       "      <td>2.550000e+02</td>\n",
       "      <td>5.800000e+01</td>\n",
       "      <td>3.976510e+05</td>\n",
       "      <td>6.553500e+04</td>\n",
       "      <td>1.593015e+15</td>\n",
       "      <td>1.593015e+15</td>\n",
       "      <td>3.963484e+06</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>4.903125e+01</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.400000e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            avg_ipt      bytes_in     bytes_out       dest_ip     dest_port  \\\n",
       "count  7.500000e+06  7.500000e+06  7.500000e+06  7.500000e+06  7.500000e+06   \n",
       "mean   1.515988e+06  1.004937e+03  4.602249e+03  1.652941e+03  1.372595e+04   \n",
       "std    4.287582e+07  4.473974e+03  6.907070e+03  8.210696e+03  1.606385e+04   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  3.000000e+00 -1.000000e+00   \n",
       "25%    0.000000e+00  0.000000e+00  4.700000e+01  7.860000e+02  1.900000e+03   \n",
       "50%    0.000000e+00  0.000000e+00  3.670000e+02  7.860000e+02  9.200000e+03   \n",
       "75%    4.500000e+00  2.700000e+02  8.688000e+03  7.860000e+02  9.200000e+03   \n",
       "max    4.294967e+09  6.551200e+04  6.553400e+04  3.969980e+05  6.553500e+04   \n",
       "\n",
       "            entropy  num_pkts_out   num_pkts_in         proto        src_ip  \\\n",
       "count  7.500000e+06  7.500000e+06  7.500000e+06  7.500000e+06  7.500000e+06   \n",
       "mean            NaN  5.413012e+00  3.285689e+00  7.047596e+00  1.653160e+04   \n",
       "std    0.000000e+00  1.262336e+01  1.204337e+01  3.440329e+00  3.993376e+04   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  1.000000e+00  3.000000e+00   \n",
       "25%    2.035156e+00  1.000000e+00  0.000000e+00  6.000000e+00  7.860000e+02   \n",
       "50%    3.089844e+00  3.000000e+00  1.000000e+00  6.000000e+00  7.860000e+02   \n",
       "75%    4.832031e+00  7.000000e+00  3.000000e+00  6.000000e+00  8.048000e+03   \n",
       "max    8.737500e+01  2.550000e+02  2.550000e+02  5.800000e+01  3.976510e+05   \n",
       "\n",
       "           src_port      time_end    time_start  total_entropy         label  \\\n",
       "count  7.500000e+06  7.500000e+06  7.500000e+06   7.500000e+06  7.500000e+06   \n",
       "mean   3.657185e+04  1.452405e+15  1.449253e+15   1.702605e+04  4.630831e-01   \n",
       "std    1.859831e+04  4.286313e+14  4.328397e+14   6.049262e+04  7.219262e-01   \n",
       "min   -1.000000e+00  1.592536e+10  1.592537e+10   0.000000e+00  0.000000e+00   \n",
       "25%    1.430600e+04  1.592637e+15  1.592633e+15   9.736174e+02  0.000000e+00   \n",
       "50%    4.446400e+04  1.592796e+15  1.592796e+15   8.341838e+03  0.000000e+00   \n",
       "75%    4.910200e+04  1.592801e+15  1.592801e+15   2.654445e+04  1.000000e+00   \n",
       "max    6.553500e+04  1.593015e+15  1.593015e+15   3.963484e+06  2.000000e+00   \n",
       "\n",
       "           duration       Year      Month           Day  \n",
       "count  7.500000e+06  7500000.0  7500000.0  7.500000e+06  \n",
       "mean            NaN     2020.0        6.0  2.154660e+01  \n",
       "std    0.000000e+00        0.0        0.0  1.217167e+00  \n",
       "min    0.000000e+00     2020.0        6.0  1.900000e+01  \n",
       "25%    4.297495e-05     2020.0        6.0  2.100000e+01  \n",
       "50%    1.149774e-04     2020.0        6.0  2.200000e+01  \n",
       "75%    2.381897e-02     2020.0        6.0  2.200000e+01  \n",
       "max    4.903125e+01     2020.0        6.0  2.400000e+01  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dest_port = data.dest_port.fillna(-1).astype('int64')\n",
    "data.src_port = data.src_port.fillna(-1).astype('int64')\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_scale = ['avg_ipt', 'bytes_in', 'bytes_out', 'num_pkts_in', 'num_pkts_out']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 = Benign, 1 = Malicious, 2 = Outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "data['label'].value_counts().plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Majority of flows use TCP (protocol 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "data['proto'].value_counts().plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns to drop: src/dest_ip, time_start/end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "# Convert categorical features (proto) to numerical form\n",
    "data_clean = pd.get_dummies(data, columns=['proto'], drop_first=True, dtype='int8')\n",
    "data_clean.drop(['src_ip', 'dest_ip', 'time_start', 'time_end'], axis=1, inplace=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_clean.drop(['label'], axis=1), data_clean['label'], test_size=0.2, random_state=42)\n",
    "scaler = MinMaxScaler()\n",
    "X_train[cols_to_scale] = scaler.fit_transform(X_train[cols_to_scale])\n",
    "X_test[cols_to_scale] = scaler.transform(X_test[cols_to_scale])\n",
    "\n",
    "X_train_normal = X_train[y_train == 0]\n",
    "X_train_outliers = X_train[y_train == 1]\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train = torch.tensor(X_train_normal.to_numpy(), dtype=torch.float32)\n",
    "X_train, X_val = X_train[:int(0.8 * len(X_train))], X_train[int(0.8 * len(X_train)):]\n",
    "\n",
    "# Create DataLoader for batch training\n",
    "train_dataset = TensorDataset(X_train)\n",
    "val_dataset = TensorDataset(X_val)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, input_dim // 2),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(input_dim // 2, input_dim // 4),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(input_dim // 4, input_dim // 8),  # New layer\n",
    "            nn.ELU()\n",
    "        )\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(input_dim // 8, input_dim // 4),  # New layer\n",
    "            nn.ELU(),\n",
    "            nn.Linear(input_dim // 4, input_dim // 2),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(input_dim // 2, input_dim),\n",
    "            nn.ELU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "# Initialize model\n",
    "input_dim = X_train.shape[1]\n",
    "model = Autoencoder(input_dim)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 101002/101002 [02:08<00:00, 784.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 32426527.914645, Validation Loss: 32787114.996060\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 101002/101002 [02:09<00:00, 780.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 32413211.231891, Validation Loss: 32399259.539206\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|        | 12266/101002 [00:15<01:54, 777.11it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[83], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m reconstructed \u001b[38;5;241m=\u001b[39m model(data)\n\u001b[1;32m     22\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(reconstructed, data)  \u001b[38;5;66;03m# MSE loss\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     26\u001b[0m total_train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/networking_llm/lib/python3.10/site-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/networking_llm/lib/python3.10/site-packages/torch/autograd/__init__.py:306\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbackward\u001b[39m(\n\u001b[1;32m    243\u001b[0m     tensors: _TensorOrTensors,\n\u001b[1;32m    244\u001b[0m     grad_tensors: Optional[_TensorOrTensors] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    248\u001b[0m     inputs: Optional[_TensorOrTensorsOrGradEdge] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    249\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    250\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Compute the sum of gradients of given tensors with respect to graph leaves.\u001b[39;00m\n\u001b[1;32m    251\u001b[0m \n\u001b[1;32m    252\u001b[0m \u001b[38;5;124;03m    The graph is differentiated using the chain rule. If any of ``tensors``\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;124;03m            were used to compute the :attr:`tensors`.\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 306\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_are_functorch_transforms_active\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    308\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackward() called inside a functorch transform. This is not \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    309\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msupported, please use functorch.grad or functorch.vjp instead \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    310\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor call backward() outside of functorch transforms.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    311\u001b[0m         )\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m grad_variables \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the autoencoder\n",
    "num_epochs = 10\n",
    "log_interval = 10_000  # Print every 10K batches\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    total_train_loss = 0\n",
    "    batch_train_losses = []\n",
    "\n",
    "    model.train()\n",
    "    #for batch_idx, batch in enumerate(train_loader):\n",
    "    for batch in tqdm(train_loader):\n",
    "        data = batch[0].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        reconstructed = model(data)\n",
    "        loss = criterion(reconstructed, data)  # MSE loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        #batch_train_losses.append(loss.item())\n",
    "\n",
    "        # Print loss every `log_interval` batches\n",
    "        #if (batch_idx + 1) % log_interval == 0:\n",
    "        #    print(f\"Batch [{batch_idx+1}/{len(train_loader)}], Loss: {np.mean(batch_train_losses):.6f}\")\n",
    "\n",
    "    epoch_train_loss = total_train_loss / len(train_loader)\n",
    "    train_losses.append(epoch_train_loss)\n",
    "\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            data = batch[0].to(device)\n",
    "            reconstructed = model(data)\n",
    "            loss = criterion(reconstructed, data)\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "    epoch_val_loss = total_val_loss / len(val_loader)\n",
    "    val_losses.append(epoch_val_loss)\n",
    "\n",
    "    print(f\"Train Loss: {epoch_train_loss:.6f}, Validation Loss: {epoch_val_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "torch.save(model.state_dict(), 'autoencoder.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>IsolationForest(contamination=0.1, max_samples=0.8, n_jobs=-1, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>IsolationForest</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.IsolationForest.html\">?<span>Documentation for IsolationForest</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>IsolationForest(contamination=0.1, max_samples=0.8, n_jobs=-1, random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "IsolationForest(contamination=0.1, max_samples=0.8, n_jobs=-1, random_state=42)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iso_forest = IsolationForest(n_estimators=100, max_samples=0.8, contamination=0.1, random_state=42, n_jobs=-1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[feature_cols], data[target_col], test_size=0.2, random_state=42)\n",
    "X_train_normal = X_train[y_train == 0]\n",
    "X_train_outliers = X_train[y_train == 1]\n",
    "\n",
    "iso_forest.fit(X_train_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7963413333333333"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iso_forest_preds = iso_forest.predict(X_test)\n",
    "iso_forest_preds = np.where(iso_forest_preds == -1, 1, 0)\n",
    "accuracy_score(y_test, iso_forest_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking columns...\n",
      "Calculating total rows...\n",
      "Computing embedding sizes...\n",
      "Checking columns...\n",
      "Calculating total rows...\n",
      "Computing embedding sizes...\n",
      "Sample input: tensor([7.5000e+00, 3.4200e+02, 3.6790e+03, 9.2000e+03, 5.4367e+00, 2.0000e+00,\n",
      "        2.0000e+00, 6.0000e+00, 5.7392e+04, 2.1861e+04, 1.5198e-02, 2.0200e+03,\n",
      "        6.0000e+00, 1.9000e+01, 6.0000e+00, 5.7392e+04, 9.2000e+03])\n",
      "Sample label: tensor([0.])\n",
      "torch.Size([64, 17]) torch.Size([64, 1])\n"
     ]
    }
   ],
   "source": [
    "class LuFlowIterableDataset(IterableDataset):\n",
    "    def __init__(self, csv_path, feature_cols, cat_cols, target_col, chunk_size=1000, train=True, train_ratio=0.8):\n",
    "        self.csv_path = Path(csv_path)\n",
    "        self.feature_cols = feature_cols\n",
    "        self.cat_cols = cat_cols\n",
    "        self.target_col = target_col\n",
    "        self.chunk_size = chunk_size\n",
    "        self.train = train\n",
    "        self.train_ratio = train_ratio\n",
    "\n",
    "        # Read header to verify columns\n",
    "        print(\"Checking columns...\")\n",
    "        self.header = pd.read_csv(self.csv_path, nrows=0).columns\n",
    "        df_sample = pd.read_csv(self.csv_path, nrows=1)\n",
    "        missing_cols = set(feature_cols + [target_col]) - set(df_sample.columns)\n",
    "        if missing_cols:\n",
    "            raise ValueError(f\"Missing columns in CSV: {missing_cols}\")\n",
    "\n",
    "        # Compute total rows\n",
    "        if not hasattr(self, \"total_rows\"):\n",
    "            print(\"Calculating total rows...\")\n",
    "            with open(csv_path, 'rb') as f:\n",
    "                self.total_rows = sum(1 for _ in f) - 1  # -1 for header\n",
    "\n",
    "        # Compute train/test split dynamically\n",
    "        self.train_cutoff = int(self.total_rows * self.train_ratio)\n",
    "\n",
    "        print(\"Computing embedding sizes...\")\n",
    "        self.num_embeddings = self._compute_categorical_sizes()\n",
    "\n",
    "    def _compute_categorical_sizes(self):\n",
    "        \"\"\"Iterate over chunks to compute unique values for categorical features (cached).\"\"\"\n",
    "        cache_file = self.csv_path.with_suffix('.cat_sizes.json')\n",
    "\n",
    "        # Load from cache if exists\n",
    "        if cache_file.exists():\n",
    "            with open(cache_file, 'r') as f:\n",
    "                return json.load(f)\n",
    "\n",
    "        unique_values = {col: set() for col in self.cat_cols}\n",
    "        total_chunks = math.ceil(self.total_rows / self.chunk_size)\n",
    "\n",
    "        for chunk in tqdm(pd.read_csv(self.csv_path, chunksize=self.chunk_size, usecols=self.cat_cols), total=total_chunks):\n",
    "            for col in self.cat_cols:\n",
    "                unique_values[col].update(chunk[col].unique())\n",
    "\n",
    "        num_embeddings = {col: len(values) for col, values in unique_values.items()}\n",
    "\n",
    "        # Save to cache\n",
    "        with open(cache_file, 'w') as f:\n",
    "            json.dump(num_embeddings, f)\n",
    "\n",
    "        return num_embeddings\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"Iterate over chunks, yielding rows dynamically.\"\"\"\n",
    "        for chunk in pd.read_csv(self.csv_path, chunksize=self.chunk_size):\n",
    "            features = chunk[self.feature_cols].to_numpy(dtype=np.float32)\n",
    "            cat_features = chunk[self.cat_cols].to_numpy(dtype=np.float32)\n",
    "            target = chunk[self.target_col].to_numpy(dtype=np.float32).reshape(-1, 1)\n",
    "\n",
    "            for i in range(len(chunk)):\n",
    "                row_idx = i + (chunk.index[0] if chunk.index is not None else 0)\n",
    "                \n",
    "                # Dynamically filter train/test split\n",
    "                if (self.train and row_idx < self.train_cutoff) or (not self.train and row_idx >= self.train_cutoff):\n",
    "                    yield np.hstack([features[i], cat_features[i]]), target[i]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total_rows\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = LuFlowIterableDataset(\n",
    "    csv_path=combined_data_path,\n",
    "    feature_cols=feature_cols,\n",
    "    cat_cols=['proto', 'src_port', 'dest_port'],\n",
    "    target_col=target_col,\n",
    "    train=True\n",
    ")\n",
    "\n",
    "test_dataset = LuFlowIterableDataset(\n",
    "    csv_path=combined_data_path,\n",
    "    feature_cols=feature_cols,\n",
    "    cat_cols=['proto', 'src_port', 'dest_port'],\n",
    "    target_col=target_col,\n",
    "    train=False\n",
    ")\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64)\n",
    "\n",
    "# Test\n",
    "for batch in train_dataloader:\n",
    "    inputs, labels = batch\n",
    "    print(f\"Sample input: {inputs[0]}\")\n",
    "    print(f\"Sample label: {labels[0]}\")\n",
    "    print(inputs.shape, labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the GitHub https://github.com/ruzzzzz/luflow\n",
    "\n",
    "#### src_ip:\n",
    "The source IP address associated with the flow. This feature is anonymised to the corresponding Autonomous System\n",
    "\n",
    "#### src_port:\n",
    "The source port number associated with the flow.\n",
    "\n",
    "#### dest_ip:\n",
    "The destination IP address associated with the flow. The feature is also anonymised in the same manner as before.\n",
    "\n",
    "#### dest_port:\n",
    "The destination port number associated with the flow\n",
    "\n",
    "#### protocol:\n",
    "The protocol number associated with the flow. For example TCP is 6\n",
    "\n",
    "#### bytes_in:\n",
    "The number of bytes transmitted from source to destination\n",
    "\n",
    "#### bytes_out:\n",
    "The number of bytes transmitted from destination to source.\n",
    "\n",
    "#### num_pkts_in:\n",
    "The packet count from source to destination\n",
    "\n",
    "#### num_pkts_out:\n",
    "The packet count from destination to source\n",
    "\n",
    "#### entropy:\n",
    "The entropy in bits per byte of the data fields within the flow. This number ranges from 0 to 8.\n",
    "\n",
    "#### total_entropy:\n",
    "The total entropy in bytes over all of the bytes in the data fields of the flow\n",
    "\n",
    "#### avg_ipt:\n",
    "The mean of the inter-packet arrival times of the flow\n",
    "\n",
    "#### time_start:\n",
    "The start time of the flow in seconds since the epoch.\n",
    "\n",
    "#### time_end:\n",
    "The end time of the flow in seconds since the epoch\n",
    "\n",
    "#### duration:\n",
    "The flow duration time, with microsecond precision\n",
    "\n",
    "#### label:\n",
    "The label of the flow, as decided by Tangerine. Either benign, outlier, or malicious"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets from https://staff.itee.uq.edu.au/marius/NIDS_datasets/#RA6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamically compute embedding dimensions\n",
    "def compute_embedding_dim(num_categories):\n",
    "    return min(50, max(1, int(num_categories ** 0.25)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkDetectionModel(nn.Module):\n",
    "    def __init__(self, output_dim, num_embeddings):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Extract categorical feature sizes\n",
    "        num_proto = num_embeddings['proto']\n",
    "        num_src_port = num_embeddings['src_port']\n",
    "        num_dest_port = num_embeddings['dest_port']\n",
    "\n",
    "        # Compute embedding dimensions\n",
    "        embed_dim_proto = compute_embedding_dim(num_proto)\n",
    "        embed_dim_src_port = compute_embedding_dim(num_src_port)\n",
    "        embed_dim_dest_port = compute_embedding_dim(num_dest_port)\n",
    "\n",
    "        # Define embedding layers\n",
    "        self.proto_embed = nn.Embedding(num_embeddings=num_proto, embedding_dim=embed_dim_proto)\n",
    "        self.src_port_embed = nn.Embedding(num_embeddings=num_src_port, embedding_dim=embed_dim_src_port)\n",
    "        self.dest_port_embed = nn.Embedding(num_embeddings=num_dest_port, embedding_dim=embed_dim_dest_port)\n",
    "\n",
    "        # Compute input dimension\n",
    "        self.input_dim = 6 + embed_dim_proto + embed_dim_src_port + embed_dim_dest_port\n",
    "        self.hidden_dim = int(math.ceil((self.input_dim + 1) * 0.67))\n",
    "\n",
    "        # Define network layers\n",
    "        self.linear_1 = nn.Linear(self.input_dim, self.hidden_dim)\n",
    "        self.linear_2 = nn.Linear(self.hidden_dim, self.hidden_dim)\n",
    "        self.out = nn.Linear(self.hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Extract continuous and categorical features\n",
    "        continuous_features = x[:, :6]\n",
    "        proto = x[:, 6].to(torch.long)\n",
    "        src_port = x[:, 7].to(torch.long)\n",
    "        dest_port = x[:, 8].to(torch.long)\n",
    "\n",
    "        # Apply embeddings\n",
    "        proto = self.proto_embed(proto)\n",
    "        src_port = self.src_port_embed(src_port)\n",
    "        dest_port = self.dest_port_embed(dest_port)\n",
    "\n",
    "        # Concatenate embeddings with continuous features\n",
    "        x = torch.cat([continuous_features, proto, src_port, dest_port], dim=-1)\n",
    "        \n",
    "        x = F.relu(self.linear_1(x))\n",
    "        x = F.relu(self.linear_2(x))\n",
    "        x = self.out(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch [1/10] Step [33681/3227447] Loss: nan Accuracy: 48.26% Elapsed: 67.8s Remaining: 6433.1s"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 129\u001b[0m\n\u001b[1;32m    126\u001b[0m scaler \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mGradScaler()  \u001b[38;5;66;03m# Handles scaling to prevent underflow\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# Usage example:\u001b[39;00m\n\u001b[0;32m--> 129\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_wandb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Set to True if using Weights & Biases\u001b[39;49;00m\n\u001b[1;32m    137\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[24], line 83\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_dataloader, test_dataloader, num_epochs, device, learning_rate, use_wandb, checkpoint_dir)\u001b[0m\n\u001b[1;32m     81\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# Slightly faster than zero_grad()\u001b[39;00m\n\u001b[1;32m     82\u001b[0m scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 83\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m scaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# Update statistics\u001b[39;00m\n",
      "File \u001b[0;32m~/networking_llm/lib/python3.10/site-packages/torch/amp/grad_scaler.py:451\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m OptState\u001b[38;5;241m.\u001b[39mREADY:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munscale_\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    455\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    457\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_opt_step(optimizer, optimizer_state, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/networking_llm/lib/python3.10/site-packages/torch/amp/grad_scaler.py:338\u001b[0m, in \u001b[0;36mGradScaler.unscale_\u001b[0;34m(self, optimizer)\u001b[0m\n\u001b[1;32m    335\u001b[0m inv_scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_scale\u001b[38;5;241m.\u001b[39mdouble()\u001b[38;5;241m.\u001b[39mreciprocal()\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m    336\u001b[0m found_inf \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfull((), \u001b[38;5;241m0.0\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_scale\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 338\u001b[0m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_unscale_grads_\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minv_scale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    340\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    341\u001b[0m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m OptState\u001b[38;5;241m.\u001b[39mUNSCALED\n",
      "File \u001b[0;32m~/networking_llm/lib/python3.10/site-packages/torch/amp/grad_scaler.py:253\u001b[0m, in \u001b[0;36mGradScaler._unscale_grads_\u001b[0;34m(self, optimizer, inv_scale, found_inf, allow_fp16)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;66;03m# To set up _amp_foreach_non_finite_check_and_unscale_, split grads by device and dtype.\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;66;03m# There could be hundreds of grads, so we'd like to iterate through them just once.\u001b[39;00m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;66;03m# However, we don't know their devices or dtypes in advance.\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# https://stackoverflow.com/questions/5029934/defaultdict-of-defaultdict\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# Google says mypy struggles with defaultdicts type annotations.\u001b[39;00m\n\u001b[1;32m    250\u001b[0m per_device_and_dtype_grads: Dict[\n\u001b[1;32m    251\u001b[0m     torch\u001b[38;5;241m.\u001b[39mdevice, Dict[torch\u001b[38;5;241m.\u001b[39mdtype, List[torch\u001b[38;5;241m.\u001b[39mTensor]]\n\u001b[1;32m    252\u001b[0m ] \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28;01mlambda\u001b[39;00m: defaultdict(\u001b[38;5;28mlist\u001b[39m))\n\u001b[0;32m--> 253\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mno_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m optimizer\u001b[38;5;241m.\u001b[39mparam_groups:\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/networking_llm/lib/python3.10/site-packages/torch/utils/_contextlib.py:156\u001b[0m, in \u001b[0;36m_NoParamDecoratorContextManager.__new__\u001b[0;34m(cls, orig_func)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, orig_func\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m orig_func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 156\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__new__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m()(orig_func)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class TrainingProgressTracker:\n",
    "    def __init__(self, num_epochs, steps_per_epoch, log_interval=10, use_wandb=False):\n",
    "        self.num_epochs = num_epochs\n",
    "        self.steps_per_epoch = steps_per_epoch\n",
    "        self.log_interval = log_interval\n",
    "        self.use_wandb = use_wandb\n",
    "        self.reset_epoch_stats()\n",
    "        \n",
    "    def reset_epoch_stats(self):\n",
    "        self.running_loss = 0.0\n",
    "        self.correct = 0\n",
    "        self.total = 0\n",
    "        self.batch_times = []\n",
    "        self.epoch_start_time = time.time()\n",
    "        \n",
    "    def update_stats(self, loss, predictions, targets, batch_size):\n",
    "        self.running_loss += loss\n",
    "        self.correct += (predictions == targets).sum().item()\n",
    "        self.total += batch_size\n",
    "        \n",
    "    def log_progress(self, epoch, step):\n",
    "        if step % self.log_interval == 0:\n",
    "            avg_loss = self.running_loss / (step + 1)\n",
    "            accuracy = (self.correct / self.total) * 100\n",
    "            elapsed = time.time() - self.epoch_start_time\n",
    "            remaining = (elapsed / (step + 1)) * (self.steps_per_epoch - step - 1)\n",
    "            \n",
    "            print(f\"\\rEpoch [{epoch+1}/{self.num_epochs}] \"\n",
    "                  f\"Step [{step+1}/{self.steps_per_epoch}] \"\n",
    "                  f\"Loss: {avg_loss:.4f} \"\n",
    "                  f\"Accuracy: {accuracy:.2f}% \"\n",
    "                  f\"Elapsed: {elapsed:.1f}s \"\n",
    "                  f\"Remaining: {remaining:.1f}s\", end=\"\")\n",
    "            \n",
    "            if self.use_wandb:\n",
    "                wandb.log({\n",
    "                    \"train/loss\": avg_loss,\n",
    "                    \"train/accuracy\": accuracy,\n",
    "                    \"train/epoch\": epoch,\n",
    "                    \"train/step\": step\n",
    "                })\n",
    "\n",
    "def train_model(model, train_dataloader, test_dataloader, num_epochs, device, \n",
    "                learning_rate=0.001, use_wandb=False, checkpoint_dir=\"checkpoints\"):\n",
    "    \n",
    "    # Setup\n",
    "    checkpoint_dir = Path(checkpoint_dir)\n",
    "    checkpoint_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scaler = torch.amp.GradScaler()\n",
    "    \n",
    "    # Initialize progress tracker\n",
    "    steps_per_epoch = len(train_dataloader)\n",
    "    tracker = TrainingProgressTracker(num_epochs, steps_per_epoch, use_wandb=use_wandb)\n",
    "    \n",
    "    # Optional: Configure automatic mixed precision\n",
    "    torch.backends.cudnn.benchmark = True  # May speed up training\n",
    "    \n",
    "    # Training loop with checkpointing\n",
    "    best_accuracy = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        tracker.reset_epoch_stats()\n",
    "        \n",
    "        # Use tqdm for overall epoch progress\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            batch_start = time.time()\n",
    "            \n",
    "            features, targets = batch\n",
    "            features = features.to(device, non_blocking=True)\n",
    "            targets = targets.to(device, dtype=torch.long, non_blocking=True)\n",
    "            \n",
    "            # Forward pass with mixed precision\n",
    "            with torch.amp.autocast(device_type=str(device)):\n",
    "                outputs = model(features)\n",
    "                loss = criterion(outputs, targets.squeeze())\n",
    "            \n",
    "            # Backward pass with gradient scaling\n",
    "            optimizer.zero_grad(set_to_none=True)  # Slightly faster than zero_grad()\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            # Update statistics\n",
    "            with torch.no_grad():\n",
    "                _, predictions = torch.max(outputs, 1)\n",
    "                tracker.update_stats(loss.item(), predictions, targets.squeeze(), targets.size(0))\n",
    "                tracker.log_progress(epoch, step)\n",
    "            \n",
    "            # Record batch processing time\n",
    "            tracker.batch_times.append(time.time() - batch_start)\n",
    "        \n",
    "        # End of epoch\n",
    "        avg_loss = tracker.running_loss / len(train_dataloader)\n",
    "        accuracy = tracker.correct / tracker.total * 100\n",
    "        avg_batch_time = np.mean(tracker.batch_times)\n",
    "        \n",
    "        print(f\"\\nEpoch {epoch+1} Summary:\")\n",
    "        print(f\"Average Loss: {avg_loss:.4f}\")\n",
    "        print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "        print(f\"Average batch processing time: {avg_batch_time:.3f}s\")\n",
    "        \n",
    "        # Save checkpoint if best accuracy\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            checkpoint_path = checkpoint_dir / f\"best_model_epoch_{epoch+1}.pt\"\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'accuracy': accuracy,\n",
    "                'loss': avg_loss,\n",
    "            }, checkpoint_path)\n",
    "            print(f\"Saved new best model checkpoint to {checkpoint_path}\")\n",
    "\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "model = NetworkDetectionModel(output_dim=3, num_embeddings=train_dataset.num_embeddings).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "scaler = torch.amp.GradScaler()  # Handles scaling to prevent underflow\n",
    "\n",
    "# Usage example:\n",
    "train_model(\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    num_epochs=num_epochs,\n",
    "    device=device,\n",
    "    learning_rate=learning_rate,\n",
    "    use_wandb=False  # Set to True if using Weights & Biases\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Network_Detection_Model(\n",
    "    output_dim=1,\n",
    "    embed_dim_bin=4, num_bin=2,\n",
    "    embed_dim_bout=4, num_bout=2,\n",
    "    embed_dim_pin=4, num_pin=2,\n",
    "    embed_dim_pout=4, num_pout=2,\n",
    "    embed_dim_proto=4, num_proto=2\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Network_Dection_Model(1, 10, 10, 10, 10, 10, 10, 10, 10, 10)\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "'''shrink = int(len(data[0])/10)\n",
    "print(shrink)\n",
    "data = data[:, :shrink]\n",
    "\n",
    "print(data.shape)'''\n",
    "\n",
    "###Finish loading data###\n",
    "\n",
    "def save_scalers(scalers, save_dir='./scalers/'):\n",
    "    \"\"\"\n",
    "    Save all scalers to pickle files.\n",
    "    \"\"\"\n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # Save scalers\n",
    "    for i, scaler in enumerate(scalers):\n",
    "        with open(f'{save_dir}X1_scaler_{H.continuous_variables[i]}.pkl', 'wb') as f:\n",
    "            pickle.dump(scaler, f)\n",
    "\n",
    "### Make train test split ###\n",
    "# Transpose to make it (samples, features) for sklearn\n",
    "data_transposed = data.T\n",
    "\n",
    "# Split with random state for reproducibility\n",
    "train_transposed, test_transposed = train_test_split(\n",
    "    data_transposed, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Transpose back to original orientation (features, samples)\n",
    "train = train_transposed.T\n",
    "test = test_transposed.T\n",
    "\n",
    "#Save test tensor for testing the model inference\n",
    "torch.save(test, U.test_data)\n",
    "\n",
    "#Turn into numpy arrays for sklearn\n",
    "train = train.numpy()\n",
    "test = test.numpy()\n",
    "\n",
    "### Scale Continuous Variables ###\n",
    "train_scalers = [] #Store scalars to be saved and used on new data\n",
    "for index in range(4):\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))  # Create a new scaler\n",
    "    train[index] = scaler.fit_transform(train[index].reshape(-1, 1)).flatten()\n",
    "    test[index] = scaler.transform(test[index].reshape(-1, 1)).flatten()\n",
    "    train_scalers.append(scaler)\n",
    "\n",
    "save_scalers(train_scalers)\n",
    "\n",
    "#Turn back into tensors\n",
    "train = torch.from_numpy(train.astype(np.float32))\n",
    "test = torch.from_numpy(test.astype(np.float32))\n",
    "\n",
    "check_feature = 4\n",
    "print(train[check_feature, torch.argmin(train[check_feature])], train[check_feature, torch.argmax(train[check_feature])])\n",
    "\n",
    "print(f'min: {train[check_feature, torch.argmin(train[check_feature])]}, max: {train[check_feature, torch.argmax(train[check_feature])]}')\n",
    "\n",
    "### Make Dataset ###\n",
    "Train_Dataset = D.LUFlow_ND_Dataset(train)\n",
    "Test_Dataset = D.LUFlow_ND_Dataset(test)\n",
    "\n",
    "### Map Values ###\n",
    "print(\"Mapping values\")\n",
    "feature_map_bin, feature_map_bout, feature_map_proto, original_bin, original_bout = preprocessing_functions.map_values(Train_Dataset)\n",
    "\n",
    "with open(U.feature_map_bin, 'w') as j:\n",
    "    json.dump(feature_map_bin, j, indent=4)\n",
    "with open(U.feature_map_bout, 'w') as j:\n",
    "    json.dump(feature_map_bout, j, indent=4)\n",
    "with open(U.feature_map_proto, 'w') as j:\n",
    "    json.dump(feature_map_proto, j, indent=4)\n",
    "\n",
    "# Explicitly assign back to ensure updates stick\n",
    "Train_Dataset.data[4, :] = torch.tensor([feature_map_bin[str(int(val.item()))] for val in Train_Dataset.data[4, :]])\n",
    "Train_Dataset.data[5, :] = torch.tensor([feature_map_bout[str(int(val.item()))] for val in Train_Dataset.data[5, :]])\n",
    "Train_Dataset.data[8, :] = torch.tensor([feature_map_proto[str(int(val.item()))] for val in Train_Dataset.data[8, :]])\n",
    "print(f'1: {Train_Dataset.data[4, torch.argmax(Train_Dataset.data[4])]}')\n",
    "print(f'2: {original_bin[torch.argmax(original_bin)]}')\n",
    "\n",
    "torch.save(Train_Dataset, U.training_dataset)\n",
    "\n",
    "### Map Test Values ###\n",
    "for i, item in enumerate(Test_Dataset.data[4]): #For bin\n",
    "    Test_Dataset.data[4, i] = preprocessing_functions.approximate_value(item, original_bin)\n",
    "\n",
    "### Map Test Values ###\n",
    "for i, item in enumerate(Test_Dataset.data[5]): #For bout\n",
    "    Test_Dataset.data[5, i] = preprocessing_functions.approximate_value(item, original_bout)\n",
    "\n",
    "# Explicitly assign back to ensure updates stick\n",
    "Test_Dataset.data[4, :] = torch.tensor([feature_map_bin[str(int(val.item()))] for val in Test_Dataset.data[4, :]])\n",
    "Test_Dataset.data[5, :] = torch.tensor([feature_map_bout[str(int(val.item()))] for val in Test_Dataset.data[5, :]])\n",
    "Test_Dataset.data[8, :] = torch.tensor([feature_map_proto[str(int(val.item()))] for val in Test_Dataset.data[8, :]])\n",
    "\n",
    "### Initialize Dataloaders ###\n",
    "Train_Loader = DataLoader(Train_Dataset, batch_size=H.BATCH_SIZE, shuffle=True)\n",
    "Test_Loader = DataLoader(Test_Dataset, batch_size=H.BATCH_SIZE, shuffle=False)\n",
    "\n",
    "### Model Initialization ###\n",
    "############################\n",
    "### Calculate Embedding Layer Sizes ###\n",
    "embed_dims = []\n",
    "num_embeds = []\n",
    "\n",
    "print(\"Calculating embedding dims\")\n",
    "for i in range(4, 9):\n",
    "    print(i)\n",
    "    feature = Train_Dataset.__getfeature__(i)\n",
    "    #print(feature[torch.argmin(feature)], feature[torch.argmax(feature)])\n",
    "    num_features = feature[torch.argmax(feature)].item()\n",
    "    print(num_features)\n",
    "\n",
    "    embed_dims.append(int(math.floor(math.sqrt(num_features+1))))\n",
    "    num_embeds.append(int(num_features)+1)\n",
    "\n",
    "print(\"Embedding parameters\")\n",
    "print(f'embed_dims: {embed_dims}')\n",
    "print(f'num_embeds: {num_embeds}')\n",
    "\n",
    "model = Model.Network_Dection_Model(H.OUTPUT_DIM, #'avg_ipt', 'entropy', 'total_entropy', 'duration', 1 output neuron\n",
    "                                    embed_dims[0], num_embeds[0], #Bin\n",
    "                                    embed_dims[1], num_embeds[1], #Bout\n",
    "                                    embed_dims[2], num_embeds[2], #Pin\n",
    "                                    embed_dims[3], num_embeds[3], #Pout\n",
    "                                    embed_dims[4], num_embeds[4]) #Proto\n",
    "model.to(device)\n",
    "#Save model parameters for loading before inference\n",
    "model_params = {'output': H.OUTPUT_DIM, \n",
    "                'embed_dims': embed_dims,\n",
    "                'num_embeds': num_embeds,\n",
    "                'original_bin': original_bin.tolist(),\n",
    "                'original_bout': original_bout.tolist(),\n",
    "                'feature_map_bin': feature_map_bin,\n",
    "                'feature_map_bout': feature_map_bout,\n",
    "                'feature_map_proto': feature_map_proto}\n",
    "\n",
    "with open(U.model_params, 'w') as j: #Save model parameters\n",
    "    json.dump(model_params, j, indent=4)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss() #Binary classification\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=H.LEARNING_RATE)\n",
    "\n",
    "#Accuracy function\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "  correct = torch.eq(y_true, y_pred).sum().item()\n",
    "  acc = (correct / len(y_pred)) * 100\n",
    "  return acc\n",
    "\n",
    "#Training Loop\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "best_val_loss = float('inf')  # Initialize best validation loss as infinity\n",
    "epochs_no_improve = 0\n",
    "\n",
    "percentage_update = .25\n",
    "update = int(len(Train_Loader) * percentage_update)\n",
    "amt = 0\n",
    "\n",
    "for epoch in range(H.EPOCHS):\n",
    "    print(f\"=== EPOCH {epoch + 1} ===\")\n",
    "    model.train()\n",
    "    training_loss = 0 #Track training loss across that batches\n",
    "    print(\"Running Training Loop\")\n",
    "    for i, batch in enumerate(Train_Loader):\n",
    "        #Forward Pass\n",
    "        x = batch[:, :9]\n",
    "        y = batch[:, 9].to(torch.long)\n",
    "        #Send to device\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        y_preds = model(x)\n",
    "        y_preds = y_preds.squeeze(1)\n",
    "\n",
    "        #Loss\n",
    "        loss = loss_fn(y_preds, y)\n",
    "        training_loss += loss.item()\n",
    "\n",
    "        #Back prop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1)%update == 0:\n",
    "            amt += 1\n",
    "            #print(f'{percentage_update*amt}%')\n",
    "\n",
    "    training_loss /= len(Train_Loader)\n",
    "    train_losses.append(training_loss)\n",
    "\n",
    "    testing_loss, test_acc = 0, 0\n",
    "    print(\"Testing the model...\")\n",
    "    model.eval()\n",
    "    for batch in Test_Loader:\n",
    "        #Forward Pass\n",
    "        x = batch[:, :9]\n",
    "        y = batch[:, 9].to(torch.long)\n",
    "\n",
    "        #Send to device\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(x)\n",
    "\n",
    "        y_preds = y_preds.squeeze(1)\n",
    "\n",
    "        #Loss\n",
    "        loss = loss_fn(y_preds, y)\n",
    "        testing_loss += loss.item()\n",
    "\n",
    "        test_acc += accuracy_fn(y_true=y, y_pred=y_preds.argmax(dim=1))\n",
    "    \n",
    "    testing_loss /= len(Test_Loader)\n",
    "    test_acc /= len(Test_Loader)\n",
    "    val_losses.append(testing_loss)\n",
    "    print(f\"Train loss: {training_loss:.6f} | Test loss: {testing_loss:.6f} | Test acc: {test_acc:.6f}%\")\n",
    "\n",
    "    #Evaluate model\n",
    "    if testing_loss < best_val_loss:\n",
    "        best_val_loss = testing_loss\n",
    "        # Save the model's parameters (state_dict) to a file\n",
    "        torch.save(model.state_dict(), (U.MODEL_FOLDER / (H.MODEL_NAME + '.pth')).resolve())\n",
    "        with open((U.MODEL_FOLDER / (H.MODEL_NAME + '_loss.txt')).resolve(), 'w') as f:\n",
    "            f.write(str(testing_loss))\n",
    "        print(f'Saved best model with validation loss: {best_val_loss:.6f}')\n",
    "        epochs_no_improve = 0  # Reset counter if improvement\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        print(f'Num epochs since improvement: {epochs_no_improve}')\n",
    "\n",
    "        #stop training if overfitting starts to happen\n",
    "        if epochs_no_improve >= H.PATIENCE:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "for x in range(H.PATIENCE):\n",
    "    train_losses.pop(-1)\n",
    "    val_losses.pop(-1)\n",
    "\n",
    "# Plotting the loss curves\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Training Loss', color='blue')\n",
    "plt.plot(val_losses, label='Validation Loss', color='orange')\n",
    "plt.title('Loss Curves')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "networking_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
